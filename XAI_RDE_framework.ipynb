{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc8111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ad0bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 5 meilleures prédictions pour l'image :\n",
      "  1. Egyptian_cat : 0.3862\n",
      "  2. tabby : 0.2892\n",
      "  3. tiger_cat : 0.1696\n",
      "  4. printer : 0.0292\n",
      "  5. hamper : 0.0179\n",
      "\n",
      "Prédiction principale (utilisée pour RDE) : Egyptian_cat (Classe 285) avec probabilité 0.3862\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Configuration et Chargement du Modèle ---\n",
    "\n",
    "# Charger le modèle ResNet50 pré-entraîné sur ImageNet\n",
    "model = tf.keras.applications.ResNet50(weights='imagenet', include_top=True)\n",
    "model.trainable = False # Geler le modèle, nous n'optimisons que le masque\n",
    "\n",
    "# Définir la taille d'entrée attendue par ResNet50\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# --- 2. Chargement et Préparation de l'Image (x) ---\n",
    "\n",
    "# Télécharger une image d'exemple\n",
    "img_url = \"data/chat_roux.jpg\"\n",
    "\n",
    "# Charger l'image et la redimensionner\n",
    "img = tf.keras.utils.load_img(img_url, target_size=IMG_SIZE)\n",
    "# 'x' est notre image de base (0-255), de forme (224, 224, 3)\n",
    "x = tf.keras.utils.img_to_array(img)\n",
    "\n",
    "# Fonction pour pré-traiter l'image pour ResNet50\n",
    "def preprocess_image(img_tensor):\n",
    "    # Ajoute la dimension batch et applique le pré-traitement ResNet\n",
    "    return tf.keras.applications.resnet50.preprocess_input(img_tensor[tf.newaxis, ...])\n",
    "\n",
    "# --- 3. Obtenir la Prédiction Originale (Phi(x)) ---\n",
    "\n",
    "# Pré-traiter l'image originale\n",
    "x_preprocessed = preprocess_image(x)\n",
    "\n",
    "# Obtenir les prédictions (qui sont des probabilités)\n",
    "original_preds = model(x_preprocessed, training=False)\n",
    "\n",
    "# Obtenir le vecteur de probabilités (en enlevant la dimension batch)\n",
    "original_probs = original_preds[0]\n",
    "\n",
    "# Obtenir l'index (j*) de la classe prédite\n",
    "j_star = tf.argmax(original_probs)\n",
    "\n",
    "# Obtenir la probabilité de cette classe\n",
    "original_prob_value = original_probs[j_star]\n",
    "\n",
    "# --- Le reste est pour l'affichage ---\n",
    "\n",
    "# Décodage pour affichage des noms\n",
    "decoded_preds = tf.keras.applications.resnet50.decode_predictions(original_preds.numpy(), top=5)\n",
    "\n",
    "print(\"Les 5 meilleures prédictions pour l'image :\")\n",
    "for i in range(5):\n",
    "    class_name = decoded_preds[0][i][1]\n",
    "    prob = decoded_preds[0][i][2]\n",
    "    print(f\"  {i+1}. {class_name} : {prob:.4f}\")\n",
    "\n",
    "# Afficher la prédiction principale qui sera utilisée pour RDE\n",
    "# (On a besoin de .numpy() pour l'afficher proprement dans le f-string)\n",
    "print(f\"\\nPrédiction principale (utilisée pour RDE) : {decoded_preds[0][0][1]} (Classe {j_star}) avec probabilité {original_prob_value.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47b1fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Hyperparamètres\n",
    "lambda_val = 0.6        # \n",
    "num_steps = 2000        # \n",
    "num_samples = 64        # [cite: 239]\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.003) # \n",
    "\n",
    "# Le masque entraînable\n",
    "s = tf.Variable(tf.ones_like(x), trainable=True)\n",
    "\n",
    "# Moyenne et écart-type pour le bruit v \n",
    "mu = tf.reduce_mean(x)\n",
    "sigma = tf.math.reduce_std(x)\n",
    "\n",
    "for step in tqdm(range(num_steps)):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # 1. Garder le masque s dans [0, 1]\n",
    "        # (Nous le faisons via assign pour que la variable 's' soit mise à jour)\n",
    "        s.assign(tf.clip_by_value(s, 0, 1)) \n",
    "        \n",
    "        # 2. Estimer l'espérance de la distorsion (Monte-Carlo)\n",
    "        distortion = 0.0\n",
    "        for _ in range(num_samples):\n",
    "            # Générer le bruit v [cite: 146, 236]\n",
    "            v = tf.random.normal(shape=x.shape, mean=mu, stddev=sigma, dtype=tf.float32)\n",
    "            \n",
    "            # Créer l'entrée perturbée y\n",
    "            y = x * s + (1 - s) * v\n",
    "            \n",
    "            # Obtenir la prédiction perturbée Phi(y)\n",
    "            # Ajout de la dimension batch (batch_size=1)\n",
    "            y_batch = y[tf.newaxis, ...] \n",
    "            perturbed_output = model(y_batch, training=False) # training=False est important\n",
    "            \n",
    "            # Obtenir le score pour la classe d'origine j*\n",
    "            perturbed_prob = perturbed_output[0, j_star]\n",
    "            \n",
    "            # Calculer la distorsion d (ex: d_2 )\n",
    "            # L'article multiplie par 100, mais c'est juste une mise à l'échelle\n",
    "            distortion += tf.square(original_prob_value - perturbed_prob)\n",
    "            \n",
    "        # Moyenne de la distorsion\n",
    "        D = distortion / num_samples\n",
    "        \n",
    "        # 3. Calculer la pénalité de parcimonie (R) [cite: 24]\n",
    "        R = lambda_val * tf.norm(s, ord=1) # Norme L1\n",
    "        \n",
    "        # 4. Perte totale\n",
    "        total_loss = D + R\n",
    "\n",
    "    # 5. Rétropropagation pour mettre à jour le masque 's'\n",
    "    # Calcule les gradients de la perte par rapport à 's'\n",
    "    gradients = tape.gradient(total_loss, [s])\n",
    "    \n",
    "    # Applique les gradients à 's'\n",
    "    optimizer.apply_gradients(zip(gradients, [s]))\n",
    "\n",
    "# 6. Le résultat final est le masque 's' optimisé\n",
    "final_explanation_mask = s.numpy() # Convertit en array NumPy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
